{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from ast import literal_eval\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import difflib\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vanshaj\\.conda\\envs\\tensorflowenv_20220122\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df1=pd.read_csv('../data/archive(1)/movies_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop([19730, 29503, 35587])\n",
    "df1['id'] = df1['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_small = pd.read_csv('../data/archive(1)/links_small.csv')\n",
    "links_small = links_small[links_small['tmdbId'].notnull()]['tmdbId'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = df1['id'].isin(links_small)\n",
    "df1 = df1[new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9099, 24)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.361006704033412"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C= df1['vote_average'].mean()\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = df1['vote_count'].quantile(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_movies = df1.copy().loc[df1['vote_count'] >= m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pop= df1.sort_values('popularity', ascending=False)\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(12,4))\n",
    "\n",
    "# plt.barh(pop['title'].head(6),pop['popularity'].head(6), align='center',\n",
    "#         color='skyblue')\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.xlabel(\"Popularity\")\n",
    "# plt.title(\"Popular Movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1['overview'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Import TfIdfVectorizer from scikit-learn\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# #Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "# tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# #Replace NaN with an empty string\n",
    "# df1['overview'] = df1['overview'].fillna('')\n",
    "# df1['tagline'] = df1['tagline'].fillna('')\n",
    "\n",
    "# df1['description'] = df1['overview'] + df1['tagline']\n",
    "# #Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "# tfidf_matrix = tfidf.fit_transform(df1['description'])\n",
    "\n",
    "# #Output the shape of tfidf_matrix\n",
    "# tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# # Compute the cosine similarity matrix\n",
    "# cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = pd.Series(df1.index, index=df1['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "#     # Get the index of the movie that matches the title\n",
    "#     idx = indices[title]\n",
    "\n",
    "#     # Get the pairwsie similarity scores of all movies with that movie\n",
    "#     sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "#     # Sort the movies based on the similarity scores\n",
    "#     sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#     # Get the scores of the 10 most similar movies\n",
    "#     sim_scores = sim_scores[1:11]\n",
    "\n",
    "#     # Get the movie indices\n",
    "#     movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "#     # Return the top 10 most similar movies\n",
    "#     return df1['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_recommendations('The Wolf of Wall Street')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['genres'] = df1['genres'].fillna('[]').apply(literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = pd.read_csv('../data/archive(1)/credits.csv')\n",
    "keywords = pd.read_csv('../data/archive(1)/keywords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords['id'] = keywords['id'].astype('int')\n",
    "credits['id'] = credits['id'].astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12600     2\n",
       "69234     2\n",
       "265189    2\n",
       "4912      2\n",
       "110428    2\n",
       "         ..\n",
       "20770     1\n",
       "4247      1\n",
       "4244      1\n",
       "12706     1\n",
       "391698    1\n",
       "Name: id, Length: 9082, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.merge(credits, on='id')\n",
    "df1 = df1.merge(keywords, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['cast'] = df1['cast'].apply(literal_eval)\n",
    "df1['crew'] = df1['crew'].apply(literal_eval)\n",
    "df1['keywords'] = df1['keywords'].apply(literal_eval)\n",
    "df1['cast_size'] = df1['cast'].apply(lambda x: len(x))\n",
    "df1['crew_size'] = df1['crew'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['director'] = df1['crew'].apply(get_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['cast'] = df1['cast'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "df1['cast'] = df1['cast'].apply(lambda x: x[:3] if len(x) >=3 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['keywords'] = df1['keywords'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['cast'] = df1['cast'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df1['director'] = df1['director'].astype('str').apply(lambda x: str.lower(x.replace(\" \", \"\")))\n",
    "df1['director'] = df1['director'].apply(lambda x: [x,x, x])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vanshaj\\AppData\\Local\\Temp/ipykernel_1128/4160031755.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  s = df1.apply(lambda x: pd.Series(x['keywords']),axis=1).stack().reset_index(level=1, drop=True)\n"
     ]
    }
   ],
   "source": [
    "s = df1.apply(lambda x: pd.Series(x['keywords']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'keyword'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "independent film        610\n",
       "woman director          550\n",
       "murder                  399\n",
       "duringcreditsstinger    327\n",
       "based on novel          318\n",
       "Name: keyword, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = s.value_counts()\n",
    "s[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s[s > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_keywords(x):\n",
    "    words = []\n",
    "    for i in x:\n",
    "        if i in s:\n",
    "            words.append(i)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['keywords'] = df1['keywords'].apply(filter_keywords)\n",
    "df1['keywords'] = df1['keywords'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "df1['keywords'] = df1['keywords'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['soup'] = df1['keywords'] + df1['cast'] + df1['director'] + df1['genres']\n",
    "df1['soup'] = df1['soup'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       jealousi toy boy friendship friend rivalri boy...\n",
       "1       boardgam disappear basedonchildren'sbook newho...\n",
       "2       fish bestfriend duringcreditssting waltermatth...\n",
       "3       basedonnovel interracialrelationship singlemot...\n",
       "4       babi midlifecrisi confid age daughter motherda...\n",
       "                              ...                        \n",
       "9214    friendship sidneypoitier wendycrewson jayo.san...\n",
       "9215    bollywood akshaykumar ileanad'cruz eshagupta t...\n",
       "9216    bollywood hrithikroshan poojahegde kabirbedi a...\n",
       "9217    monster godzilla giantmonst destruct kaiju hir...\n",
       "9218    music documentari paulmccartney ringostarr joh...\n",
       "Name: soup, Length: 9219, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['soup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "count_matrix = count.fit_transform(df1['soup'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim1 = np.array(cosine_sim)\n",
    "\n",
    "with open('test.npy', 'wb') as f:\n",
    "    np.save(f,cosine_sim1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.load('test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.reset_index()\n",
    "titles = df1['title']\n",
    "indices = pd.Series(df1.index, index=df1['title'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # Get the index of the movie that matches the title\n",
    "    # idx = indices[title]\n",
    "    list_of_all_titles = df1['title'].tolist()\n",
    "    closest_match = difflib.get_close_matches(title,list_of_all_titles)[0]\n",
    "\n",
    "    idx = df1.index[df1['title']==closest_match].tolist()[0]\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return df1['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3794                                         Zoolander\n",
      "9130                                       Zoolander 2\n",
      "336                                      Reality Bites\n",
      "652                                      The Cable Guy\n",
      "8550                   The Secret Life of Walter Mitty\n",
      "4839                                            Duplex\n",
      "7297    Night at the Museum: Battle of the Smithsonian\n",
      "5204                                              Envy\n",
      "8002                                       Tower Heist\n",
      "5159                                   Starsky & Hutch\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(get_recommendations('Thor: Love and Thunder'))\n",
    "except:\n",
    "    print('No such recommendation')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/rounakbanik/movie-recommender-systems/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('tensorflowenv_20220122')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c2e8fcb74b459646169e5c12b1b3bad8bafdc0d857aabfcf8ac08160d16192a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
